# -*- coding: utf-8 -*-
"""Phone Kart.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_pHNUTA1TgjJNVzdBsQ-lL_wbljKjcQW

# **PHONE KART**

# **Installing Python Libraries**

**pandas:** Used for data manipulation and analysis.

**numpy:** Used for numerical operations.

**matplotlib:** Used for creating static, interactive, and animated visualizations in Python.

**seaborn:** A statistical data visualization library based on matplotlib.

**scikit-learn:** A machine learning library providing tools for model building and evaluation.
"""

pip install pandas numpy matplotlib seaborn scikit-learn

"""# **Importing Python libraries for data manipulation, visualization, and machine learning**

**Model Selection:** for splitting the data into training and testing sets.

**Standard Scaler:** to scale the features of the dataset.

**Logistic Regression, Random Forest Classifier and Gradient Boosting Classifier** are imported to implement different machine learning models.

**Metrics**: for evaluating the performance of the models using classification reports, confusion matrices, and accuracy scores.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import pyplot

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

"""# **Loading The Dataset**
# Loading a CSV file into a pandas DataFrame
"""

df = pd.read_csv('/content/drive/MyDrive/ML Datasets/Phone Pricing dataset.csv')

"""# Displaying the first 5 rows of the Data"""

display(df.head())

"""# Displaying the basic information of the Data"""

display(df.info())

"""# Calculating and Displaying descriptive statistics for each numerical column in the Data

**count:** The number of non-null values in each column.

**mean:** The average value.

**std:** The standard deviation, which measures the spread of the data.

**min:** The minimum value.

**25%, 50%, 75%:** The quartiles, representing the 25th, 50th (median), and 75th percentiles.

**max:** The maximum value.

This helps in understanding the range, variability, and potential outliers in each feature.


"""

display(df.describe())

"""# Calculating and displaying the distribution of the target variable.

**0:** low

**1:** medium

**2:** high

**3:** very high
"""

display(df['price_range'].value_counts())

"""# Checking for missing values"""

display(df.isnull().sum())

"""# Splitting and scaling the data"""

# Here the data will be split into input features and output features.
# Here we drop price range from X as X represents input factors.
# Similarly we define Y as price range as Y represents the output features.
x = df.drop('price_range', axis=1)
y = df['price_range']

"""# Initializing a Standard Scaler object"""

# Here, we have scaled the input features according to their contribution to the final output.
scaler = StandardScaler()
x_scaled = scaler.fit_transform(x)

"""# Generating a heatmap to visualize the correlation between the features

"""

plt.figure(figsize=(16, 12))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Feature Correlation with Target")
plt.show()

"""# **Training The Model**

# Splitting the dataset into training and testing sets
"""

# Here we have used random state = 42 to reproduce the same results everytime we run the project.
x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=42)

"""# Training and evaluating a Linear Regression model"""

linreg = LinearRegression()
linreg.fit(x_train, y_train)
y_pre_lr = np.clip(np.round(linreg.predict(x_test)), 0, 3).astype(int)
# Here we round off the value of prediction and then clip them to 0 to 3 in the integer format.

print("Linear Regression Accuracy:", accuracy_score(y_test, y_pre_lr))

"""# Training and evaluating a Random Forest Classifier model"""

rfc = RandomForestClassifier(n_estimators=100, random_state=42)
# Here we have used random state = 42 to reproduce the same results everytime we run the project.

rfc.fit(x_train, y_train)
y_pre_rf = rfc.predict(x_test)
print("Random Forest Accuracy:", accuracy_score(y_test, y_pre_rf))

"""# Training and evaluating a Gradient Boosting Classifier model"""

gbc = GradientBoostingClassifier(n_estimators=100, random_state=42)
# Here we have used random state = 42 to reproduce the same results everytime we run the project.

gbc.fit(x_train, y_train)
y_pre_gb = gbc.predict(x_test)
print("Gradient Boosting Accuracy:", accuracy_score(y_test, y_pre_gb))

"""# Generating Bar Plot to compare the accuracy of the three machine learning models: Linear Regression, Random Forest, and Gradient Boosting."""

# Here we compare the accuracy of the models by plotting their accuracy on a single bar graph to get the best results.
# Here we created two lists of names and accuracies which will be appended as we fit each of the models.

names_phone_kart = ['Linear Regression', 'Random Forest', 'Gradient Boosting']
res_phone_kart = [accuracy_score(y_test, y_pre_lr), accuracy_score(y_test, y_pre_rf), accuracy_score(y_test, y_pre_gb)]

pyplot.figure(figsize=(8, 6))
pyplot.bar(names_phone_kart, res_phone_kart, color=['skyblue', 'lightgreen', 'salmon'], width = 0.6)
pyplot.ylabel('Accuracy')
pyplot.title("Phone Price Range Prediction Algorithm Comparison")
pyplot.ylim(0.8, 1)
pyplot.show()

"""# Evaluating the models to print a classification report and display a confusion matrix"""

def evaluate_model(y_true, y_pre, model_name):
    print(f"\n{model_name} Classification Report:")
    print(classification_report(y_true, y_pre))
    cm = confusion_matrix(y_true, y_pre)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')
# Here fmt = 'd' helps to convert the output data to integers.

    plt.title(f'{model_name} Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

"""# Linear Regression Model"""

evaluate_model(y_test, y_pre_lr, "Linear Regression")

"""# Random Forest Classification Model"""

evaluate_model(y_test, y_pre_rf, "Random Forest")

"""# Gradient Boosting Classifier Model"""

evaluate_model(y_test, y_pre_gb, "Gradient Boosting")

"""# Calculating and visualizing the feature importances from the trained Random Forest Classifier model"""

# Here we have plotted a bar graph comparing the contribution of different features towards the final output.
importances = rfc.feature_importances_
# Here coef refers to magnitude of coefficient which represents the importance of each feature in a linear model.

features = x.columns
indices = np.argsort(importances)[::-1]
# Here we sort the features importance in the descending order and return the indices.

plt.figure(figsize=(10, 6))
plt.title("Feature Importances")
plt.bar(range(x.shape[1]), importances[indices])
plt.xticks(range(x.shape[1]), features[indices], rotation=90)
# Here we rotate the labels by 90 degrees to make them readable.

plt.xlabel("Features")
plt.ylabel("Importance")
plt.tight_layout()
# Here we adjust the plot parameters automatically.

plt.show()

"""# **Predicting on New Data**"""

sample = pd.DataFrame({
  'battery_power': [1168],
    'blue': [0],
    'clock_speed': [1.3],
    'dual_sim': [0],
    'fc': [9],
    'four_g': [0],
    'int_memory': [61],
    'm_dep': [0.1],
    'mobile_wt': [90],
    'n_cores': [8],
    'pc': [10],
    'px_height': [159],
    'px_width': [1578],
    'ram': [2941],
    'sc_h': [9],
    'sc_w': [4],
    'talk_time': [17],
    'three_g': [0],
    'touch_screen': [0],
    'wifi': [1]   })
# Here we enter the new mobile sample data.

sample_scaled = scaler.transform(sample)
# Here we scale the input data as model was trained on scaled data.

prediction = gbc.predict(sample_scaled)[0]
# Here the model is trained to make the prediction.

price_map = {0: "Low", 1: "Medium", 2: "High", 3: "Very High"  }
# Here we map the output to the human readable string.

sample['Predicted Price Range'] = price_map[prediction]

print("Mobile Data with Prediction:")
display(sample)